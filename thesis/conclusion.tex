\chapter{Conclusion}\label{chapter:conclusion}

\section{Concluding Remarks}

This thesis deals with the design and implementation of a distributed system that allows the execution of low latency SQL queries that join a real-time data stream and an external dataset. The use case for which we implement this system is the execution of topN SQL queries that join a real-time network data stream, generated by sampling IXP traffic, and external datasets containing Autonomous System and DNS information. 

To achieve low query latency, we implemented a Storm topology that reads the data stream from a Kafka topic, performs the join in real time and stores the denormalized data stream at a Phoenix table in HBase. This allows all subsequent queries to be performed without the need to compute the join on query time. The system's scalability and fault tolerance are ensured by using Kafka, Storm and HBase for its implementation. Storm also provides extesibility to the system, allowing us to easily add more external datasets of any size that are joined with the network data stream.

We also applied a combination of optimizations to the HBase cluster and the Phoenix table that further reduce query latency. More specifically, we use multiple column families for the Phoenix table to reduce the data cached during each query. We enabled HDFS short-circuit for faster local reads. To increase read and write performance, we also enabled compression and salting on the Phoenix table and disabled data block encoding. In addition to that, we disabled BlockCache on the Reverse DNS table, to allow the Phoenix table to fully take advantage of the cache.

Finally, we evaluated the performance of the system using a cluster of VMs. We recorded and analyzed the performance for every component of the system, including the Kafka topic, the Storm topology and the Phoenix table, while tuning the system and applying the aforementioned optimizations. The results demonstrated that our system can process packets with a satisfactory throughput, with a low total system latency and allows queries to be executed with low execute latency. We also experimented with the system's scalability with the cluster size, however in our evaluation setup it did not demonstrate linear scaling for large cluster sizes, since the aggregate disk I/O throughput was not increasing proportionally with cluster size.


\section{Future Work}

Regarding future work that can evolve our system, propose the following:
\begin{itemize}
\item Properly evaluate the system's scalability using a cluster of physical nodes, each one assigned with a dedicated disk.
\item Compare the Storm topology of our system to implementations in other distributed stream processing frameworks, such as Storm Trident \cite{trident}, Spark Streaming \cite{spark_streaming} and Samza \cite{samza}. Storm Trident and Spark Streaming are batching the data stream to achieve higher throughput.
\item Compare Phoenix to other low latency SQL-on-HBase querying engines, such as Apache Drill \cite{drill} and Spark SQL \cite{spark_sql}.
\end{itemize}


\cleardoublepage
